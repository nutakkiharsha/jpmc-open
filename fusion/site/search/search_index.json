{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyFusion \u00b6 PyFusion is the Python SDK for the Fusion platform API. Installation \u00b6 pip install pyfusion Fusion by J.P. Morgan is a cloud-native data platform for institutional investors, providing end-to-end data management, analytics, and reporting solutions across the investment lifecycle. The platform allows clients to seamlessly integrate and combine data from multiple sources into a single data model that delivers the benefits and scale and reduces costs, along with the ability to more easily unlock timely analysis and insights. Fusion's open data architecture supports flexible distribution, including partnerships with cloud and data providers, all managed by J.P. Morgan data experts. For more information, please visit fusion.jpmorgan.com","title":"Home"},{"location":"#pyfusion","text":"PyFusion is the Python SDK for the Fusion platform API.","title":"PyFusion"},{"location":"#installation","text":"pip install pyfusion Fusion by J.P. Morgan is a cloud-native data platform for institutional investors, providing end-to-end data management, analytics, and reporting solutions across the investment lifecycle. The platform allows clients to seamlessly integrate and combine data from multiple sources into a single data model that delivers the benefits and scale and reduces costs, along with the ability to more easily unlock timely analysis and insights. Fusion's open data architecture supports flexible distribution, including partnerships with cloud and data providers, all managed by J.P. Morgan data experts. For more information, please visit fusion.jpmorgan.com","title":"Installation"},{"location":"api/","text":"Top-level package for fusion. fusion \u00b6 Main Fusion module. APIConnectError \u00b6 APIConnectError exception wrapper to handle API connection errors. Parameters: Name Type Description Default Exception Exception to wrap. required APIRequestError \u00b6 APIRequestError exception wrapper to handle API request erorrs. Parameters: Name Type Description Default Exception Exception to wrap. required APIResponseError \u00b6 APIResponseError exception wrapper to handle API response errors. Parameters: Name Type Description Default Exception Exception to wrap. required CredentialError \u00b6 CredentialError exception wrapper to handle errors in credentials provided for authentication. Parameters: Name Type Description Default Exception Exception to wrap. required Fusion \u00b6 Core Fusion class for API access. __init__ ( self , credentials = 'config/client_credentials.json' , root_url = 'https://fusion-api.jpmorgan.com/fusion/v1/' , download_folder = 'downloads' , log_level = 40 ) special \u00b6 Constructor to instantiate a new Fusion object. Parameters: Name Type Description Default credentials Union[str, dict] A path to a credentials file or a dictionary containing the required keys. Defaults to 'config/client_credentials.json'. 'config/client_credentials.json' root_url str The API root URL. Defaults to \"https://fusion-api.jpmorgan.com/fusion/v1/\". 'https://fusion-api.jpmorgan.com/fusion/v1/' download_folder str The folder path where downloaded data files are saved. Defaults to \"downloads\". 'downloads' log_level int Set the logging level. Defaults to logging.ERROR. 40 Source code in fusion/fusion.py def __init__ ( self , credentials : Union [ str , dict ] = 'config/client_credentials.json' , root_url : str = \"https://fusion-api.jpmorgan.com/fusion/v1/\" , download_folder : str = \"downloads\" , log_level : int = logging . ERROR , ) -> None : \"\"\"Constructor to instantiate a new Fusion object. Args: credentials (Union[str, dict], optional): A path to a credentials file or a dictionary containing the required keys. Defaults to 'config/client_credentials.json'. root_url (_type_, optional): The API root URL. Defaults to \"https://fusion-api.jpmorgan.com/fusion/v1/\". download_folder (str, optional): The folder path where downloaded data files are saved. Defaults to \"downloads\". log_level (int, optional): Set the logging level. Defaults to logging.ERROR. \"\"\" self . root_url = root_url self . download_folder = download_folder Path ( download_folder ) . mkdir ( parents = True , exist_ok = True ) if logger . hasHandlers (): logger . handlers . clear () file_handler = logging . FileHandler ( filename = \"fusion_sdk.log\" ) logging . addLevelName ( VERBOSE_LVL , \"VERBOSE\" ) stdout_handler = logging . StreamHandler ( sys . stdout ) formatter = logging . Formatter ( \" %(asctime)s . %(msecs)03d %(name)s : %(levelname)s %(message)s \" , datefmt = \"%Y-%m- %d %H:%M:%S\" ) stdout_handler . setFormatter ( formatter ) logger . addHandler ( stdout_handler ) logger . addHandler ( file_handler ) logger . setLevel ( log_level ) if isinstance ( credentials , FusionCredentials ): self . credentials = credentials else : self . credentials = FusionCredentials . from_object ( credentials ) self . session = _get_session ( self . credentials , self . root_url ) catalog_resources ( self , catalog = 'common' , output = False ) \u00b6 List the resources contained within the catalog, for example products and datasets. Parameters: Name Type Description Default catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each resource within the catalog Source code in fusion/fusion.py def catalog_resources ( self , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the resources contained within the catalog, for example products and datasets. Args: catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each resource within the catalog \"\"\" url = f ' { self . root_url } catalogs/ { catalog } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df dataset_resources ( self , dataset , catalog = 'common' , output = False ) \u00b6 List the resources available for a dataset, currently this will always be a datasetseries. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each resource Source code in fusion/fusion.py def dataset_resources ( self , dataset : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the resources available for a dataset, currently this will always be a datasetseries. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each resource \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df datasetmember_resources ( self , dataset , series , catalog = 'common' , output = False ) \u00b6 List the available resources for a datasetseries member. Parameters: Name Type Description Default dataset str A dataset identifier required series str The datasetseries identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each datasetseries member resource. Currently this will always be distributions. Source code in fusion/fusion.py def datasetmember_resources ( self , dataset : str , series : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the available resources for a datasetseries member. Args: dataset (str): A dataset identifier series (str): The datasetseries identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each datasetseries member resource. Currently this will always be distributions. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries/ { series } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df download ( self , dataset , dt_str = 'latest' , dataset_format = 'parquet' , catalog = 'common' , n_par = 5 , show_progress = True , force_download = False , download_folder = None ) \u00b6 Downloads the requested distributions of a dataset to disk. Parameters: Name Type Description Default dataset str A dataset identifier required dt_str str Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. 'latest' dataset_format str The file format, e.g. CSV or Parquet. Defaults to 'parquet'. 'parquet' catalog str A catalog identifier. Defaults to 'common'. 'common' n_par int Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. 5 show_progress bool Display a progress bar during data download Defaults to True. True force_download bool If True then will always download a file even if it is already on disk. Defaults to True. False download_folder str The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init None Source code in fusion/fusion.py def download ( self , dataset : str , dt_str : str = 'latest' , dataset_format : str = 'parquet' , catalog : str = 'common' , n_par : int = DEFAULT_PARALLELISM , show_progress : bool = True , force_download : bool = False , download_folder : str = None , ): \"\"\"Downloads the requested distributions of a dataset to disk. Args: dataset (str): A dataset identifier dt_str (str, optional): Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'. catalog (str, optional): A catalog identifier. Defaults to 'common'. n_par (int, optional): Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. show_progress (bool, optional): Display a progress bar during data download Defaults to True. force_download (bool, optional): If True then will always download a file even if it is already on disk. Defaults to True. download_folder (str, optional): The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in __init__ Returns: \"\"\" required_series = self . _resolve_distro_tuples ( dataset , dt_str , dataset_format , catalog ) if not download_folder : download_folder = self . download_folder Path ( download_folder ) . mkdir ( parents = True , exist_ok = True ) download_spec = [ ( self . credentials , _distribution_to_url ( self . root_url , series [ 1 ], series [ 2 ], series [ 3 ], series [ 0 ]), _distribution_to_filename ( download_folder , series [ 1 ], series [ 2 ], series [ 3 ], series [ 0 ]), force_download , ) for series in required_series ] if show_progress : loop = tqdm ( download_spec ) else : loop = download_spec logger . log ( VERBOSE_LVL , f 'Beginning { len ( loop ) } downloads in batches of { n_par } ' , ) res = Parallel ( n_jobs = n_par )( delayed ( _stream_single_file_new_session )( * spec ) for spec in loop ) return res list_catalogs ( self , output = False ) \u00b6 Lists the catalogs available to the API account. Parameters: Name Type Description Default output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each catalog Source code in fusion/fusion.py def list_catalogs ( self , output : bool = False ) -> pd . DataFrame : \"\"\"Lists the catalogs available to the API account. Args: output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each catalog \"\"\" url = f ' { self . root_url } catalogs/' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df list_dataset_attributes ( self , dataset , catalog = 'common' , output = False ) \u00b6 Returns the list of attributes that are in the dataset. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each attribute Source code in fusion/fusion.py def list_dataset_attributes ( self , dataset : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"Returns the list of attributes that are in the dataset. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each attribute \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /attributes' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df list_datasetmembers ( self , dataset , catalog = 'common' , output = False , max_results =- 1 ) \u00b6 List the available members in the dataset series. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each dataset member. Source code in fusion/fusion.py def list_datasetmembers ( self , dataset : str , catalog : str = 'common' , output : bool = False , max_results : int = - 1 ) -> pd . DataFrame : \"\"\"List the available members in the dataset series. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each dataset member. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries' df = Fusion . _call_for_dataframe ( url , self . session ) if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df list_datasets ( self , contains = None , id_contains = False , catalog = 'common' , output = False , max_results =- 1 ) \u00b6 summary . Parameters: Name Type Description Default contains Union[str, list] A string or a list of strings that are dataset identifiers to filter the datasets list. If a list is provided then it will return datasets whose identifier matches any of the strings. Defaults to None. None id_contains bool Filter datasets only where the string(s) are contained in the identifier, ignoring description. False catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each dataset. Source code in fusion/fusion.py def list_datasets ( self , contains : Union [ str , list ] = None , id_contains : bool = False , catalog : str = 'common' , output : bool = False , max_results : int = - 1 , ) -> pd . DataFrame : \"\"\"_summary_. Args: contains (Union[str, list], optional): A string or a list of strings that are dataset identifiers to filter the datasets list. If a list is provided then it will return datasets whose identifier matches any of the strings. Defaults to None. id_contains (bool): Filter datasets only where the string(s) are contained in the identifier, ignoring description. catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each dataset. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets' df = Fusion . _call_for_dataframe ( url , self . session ) if contains : if isinstance ( contains , list ): contains = \"|\" . join ( f ' { s } ' for s in contains ) if id_contains : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False )] else : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False ) | df [ 'description' ] . str . contains ( contains , case = False ) ] if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df list_distributions ( self , dataset , series , catalog = 'common' , output = False ) \u00b6 List the available distributions (downloadable instances of the dataset with a format type). Parameters: Name Type Description Default dataset str A dataset identifier required series str The datasetseries identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each distribution. Source code in fusion/fusion.py def list_distributions ( self , dataset : str , series : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the available distributions (downloadable instances of the dataset with a format type). Args: dataset (str): A dataset identifier series (str): The datasetseries identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each distribution. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries/ { series } /distributions' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df list_products ( self , contains = None , id_contains = False , catalog = 'common' , output = False , max_results =- 1 ) \u00b6 Get the products contained in a catalog. A product is a grouping of datasets. Parameters: Name Type Description Default contains Union[str, list] A string or a list of strings that are product identifiers to filter the products list. If a list is provided then it will return products whose identifier matches any of the strings. Defaults to None. None id_contains bool Filter datasets only where the string(s) are contained in the identifier, ignoring description. False catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each product Source code in fusion/fusion.py def list_products ( self , contains : Union [ str , list ] = None , id_contains : bool = False , catalog : str = 'common' , output : bool = False , max_results : int = - 1 , ) -> pd . DataFrame : \"\"\"Get the products contained in a catalog. A product is a grouping of datasets. Args: contains (Union[str, list], optional): A string or a list of strings that are product identifiers to filter the products list. If a list is provided then it will return products whose identifier matches any of the strings. Defaults to None. id_contains (bool): Filter datasets only where the string(s) are contained in the identifier, ignoring description. catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each product \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /products' df = Fusion . _call_for_dataframe ( url , self . session ) if contains : if isinstance ( contains , list ): contains = \"|\" . join ( f ' { s } ' for s in contains ) if id_contains : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False )] else : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False ) | df [ 'description' ] . str . contains ( contains , case = False ) ] if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df load ( self , dataset , dt_str = 'latest' , dataset_format = 'parquet' , catalog = 'common' , n_par = 5 , show_progress = True , columns = None , force_download = False , download_folder = None , ** kwargs ) \u00b6 Gets distributions for a specified date or date range and returns the data as a dataframe. Parameters: Name Type Description Default dataset str A dataset identifier required dt_str str Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. 'latest' dataset_format str The file format, e.g. CSV or Parquet. Defaults to 'parquet'. 'parquet' catalog str A catalog identifier. Defaults to 'common'. 'common' n_par int Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. 5 show_progress bool Display a progress bar during data download Defaults to True. True dry_run bool description . Defaults to True required columns List description . Defaults to None None force_download bool If True then will always download a file even if it is already on disk. Defaults to True. False download_folder str The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init None Returns: Type Description pandas.DataFrame a dataframe containing the requested data. If multiple dataset instances are retrieved then these are concatenated first. Source code in fusion/fusion.py def load ( self , dataset : str , dt_str : str = 'latest' , dataset_format : str = 'parquet' , catalog : str = 'common' , n_par : int = DEFAULT_PARALLELISM , show_progress : bool = True , columns : List = None , force_download : bool = False , download_folder : str = None , ** kwargs , ): \"\"\"Gets distributions for a specified date or date range and returns the data as a dataframe. Args: dataset (str): A dataset identifier dt_str (str, optional): Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'. catalog (str, optional): A catalog identifier. Defaults to 'common'. n_par (int, optional): Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. show_progress (bool, optional): Display a progress bar during data download Defaults to True. dry_run (bool, optional): _description_. Defaults to True columns (List, optional): _description_. Defaults to None force_download (bool, optional): If True then will always download a file even if it is already on disk. Defaults to True. download_folder (str, optional): The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in __init__ Returns: pandas.DataFrame: a dataframe containing the requested data. If multiple dataset instances are retrieved then these are concatenated first. \"\"\" if not download_folder : download_folder = self . download_folder download_res = self . download ( dataset , dt_str , dataset_format , catalog , n_par , show_progress , force_download , download_folder ) if not all ( res [ 0 ] for res in download_res ): failed_res = [ res for res in download_res if not res [ 0 ]] raise Exception ( f \"Not all downloads were successfully completed. \" f \"Re-run to collect missing files. The following failed: \\n { failed_res } \" ) files = [ res [ 1 ] for res in download_res ] pd_read_fn_map = { 'csv' : pd . read_csv , 'parquet' : pd . read_parquet , 'parq' : pd . read_parquet , 'json' : pd . read_json , } pd_read_default_kwargs : Dict [ str , Dict [ str , object ]] = { 'csv' : { 'sep' : ',' , 'header' : 0 , 'low_memory' : True }, 'parquet' : { 'columns' : columns }, } pd_read_default_kwargs [ 'parq' ] = pd_read_default_kwargs [ 'parquet' ] pd_reader = pd_read_fn_map . get ( dataset_format ) pd_read_kwargs = pd_read_default_kwargs . get ( dataset_format , {}) if not pd_reader : raise Exception ( f 'No pandas function to read file in format { dataset_format } ' ) pd_read_kwargs . update ( kwargs ) dataframes = ( pd_reader ( f , ** pd_read_kwargs ) for f in files ) df = pd . concat ( dataframes , ignore_index = True ) return df FusionCredentials \u00b6 Utility functions to manage credentials. __init__ ( self , client_id = None , client_secret = None , resource = None , auth_url = None , proxies = {}) special \u00b6 Constuctor for the FusionCredentials authentication management class. Parameters: Name Type Description Default client_id str A valid OAuth client identifier. Defaults to None. None client_secret str A valid OAuth client secret. Defaults to None. None resource str The OAuth audience. Defaults to None. None auth_url str URL for the OAuth authentication server. Defaults to None. None proxies dict Any proxy servers required to route HTTP and HTTPS requests to the internet. {} Source code in fusion/fusion.py def __init__ ( self , client_id : str = None , client_secret : str = None , resource : str = None , auth_url : str = None , proxies = {}, ) -> None : \"\"\"Constuctor for the FusionCredentials authentication management class. Args: client_id (str, optional): A valid OAuth client identifier. Defaults to None. client_secret (str, optional): A valid OAuth client secret. Defaults to None. resource (str, optional): The OAuth audience. Defaults to None. auth_url (str, optional): URL for the OAuth authentication server. Defaults to None. proxies (dict, optional): Any proxy servers required to route HTTP and HTTPS requests to the internet. \"\"\" self . client_id = client_id self . client_secret = client_secret self . resource = resource self . auth_url = auth_url self . proxies = proxies from_dict ( credentials ) staticmethod \u00b6 Create a credentials object from a dictionary. Parameters: Name Type Description Default credentials dict A dictionary containing the requried keys: client_id, client_secret, resource, auth_url, and optionally proxies required Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_dict ( credentials : dict ): \"\"\"Create a credentials object from a dictionary. Args: credentials (dict): A dictionary containing the requried keys: client_id, client_secret, resource, auth_url, and optionally proxies Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" client_id = credentials [ 'client_id' ] client_secret = credentials [ 'client_secret' ] resource = credentials [ 'resource' ] auth_url = credentials [ 'auth_url' ] proxies = credentials . get ( 'proxies' ) creds = FusionCredentials ( client_id , client_secret , resource , auth_url , proxies ) return creds from_file ( credentials_file = 'config/client.credentials.json' ) staticmethod \u00b6 Create a credentils object from a file. Parameters: Name Type Description Default credentials_file str Path (absolute or relative) and filename to load credentials from. Defaults to 'config/client.credentials.json'. 'config/client.credentials.json' Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_file ( credentials_file : str = 'config/client.credentials.json' ): \"\"\"Create a credentils object from a file. Args: credentials_file (str, optional): Path (absolute or relative) and filename to load credentials from. Defaults to 'config/client.credentials.json'. Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" with open ( credentials_file , 'r' ) as credentials : data = json . load ( credentials ) credentials = FusionCredentials . from_dict ( data ) return credentials from_object ( credentials_source ) staticmethod \u00b6 Utility function that will determine how to create a credentials object based on data passed. Parameters: Name Type Description Default credentials_source Union[str, dict] A string which could be a filename or a JSON object, or a dictionary. required Exceptions: Type Description CredentialError Exception raised when the provided credentials is not one of the supported types Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_object ( credentials_source : Union [ str , dict ]): \"\"\"Utility function that will determine how to create a credentials object based on data passed. Args: credentials_source (Union[str, dict]): A string which could be a filename or a JSON object, or a dictionary. Raises: CredentialError: Exception raised when the provided credentials is not one of the supported types Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" if isinstance ( credentials_source , dict ): return FusionCredentials . from_dict ( credentials_source ) elif isinstance ( credentials_source , str ): if _is_json ( credentials_source ): return FusionCredentials . from_dict ( json . loads ( credentials_source )) else : return FusionCredentials . from_file ( credentials_source ) raise CredentialError ( f 'Could not resolve the credentials provided: { credentials_source } ' ) generate_credentials_file ( credentials_file = 'config/client_credentials.json' , client_id = None , client_secret = None , resource = None , auth_url = None , proxies = None ) staticmethod \u00b6 Utility function to generate credentials file that can be used for authentication. Parameters: Name Type Description Default credentials_file str The path and filename to store the credentials under. Path may be absolute or relative to current working directory. Defaults to 'config/client_credentials.json'. 'config/client_credentials.json' client_id str A valid OAuth client identifier. Defaults to None. None client_secret str A valid OAuth client secret. Defaults to None. None resource str The OAuth audience. Defaults to None. None auth_url str URL for the OAuth authentication server. Defaults to None. None proxies str Any proxy servers required to route HTTP and HTTPS requests to the internet. Defaults to {}. Keys are http and https None Exceptions: Type Description CredentialError Exception to handle missing values required for authentication. Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def generate_credentials_file ( credentials_file : str = 'config/client_credentials.json' , client_id : str = None , client_secret : str = None , resource : str = None , auth_url : str = None , proxies : str = None , ): \"\"\"Utility function to generate credentials file that can be used for authentication. Args: credentials_file (str, optional): The path and filename to store the credentials under. Path may be absolute or relative to current working directory. Defaults to 'config/client_credentials.json'. client_id (str, optional): A valid OAuth client identifier. Defaults to None. client_secret (str, optional): A valid OAuth client secret. Defaults to None. resource (str, optional): The OAuth audience. Defaults to None. auth_url (str, optional): URL for the OAuth authentication server. Defaults to None. proxies (dict, optional): Any proxy servers required to route HTTP and HTTPS requests to the internet. Defaults to {}. Keys are http and https Raises: CredentialError: Exception to handle missing values required for authentication. Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" if not client_id : raise CredentialError ( 'A valid client_id is required' ) if not client_secret : raise CredentialError ( 'A valid client secret is required' ) if not resource : raise CredentialError ( 'A valid resource is required' ) if not auth_url : raise CredentialError ( 'A valid authentication server URL is required' ) data = dict ( { 'client_id' : client_id , 'client_secret' : client_secret , 'resource' : resource , 'auth_url' : auth_url } ) if proxies : proxies_dict = json . loads ( proxies ) data [ 'proxies' ] = proxies_dict json_data = json . dumps ( data ) with open ( credentials_file , 'w' ) as credentialsfile : credentialsfile . write ( json_data ) credentials = FusionCredentials ( client_id , client_secret , resource , auth_url ) return credentials FusionOAuthAdapter \u00b6 An OAuth adapter to manage authentication and session tokens. __init__ ( self , credentials , proxies = {}, refresh_within_seconds = 5 , auth_retries = None , * args , ** kwargs ) special \u00b6 Class constructor to create a FusionOAuthAdapter object. Parameters: Name Type Description Default credentials Union[fusion.fusion.FusionCredentials, str, dict] Valid user credentials to authenticate. required proxies dict Specify a proxy if required to access the authentication server. Defaults to {}. {} refresh_within_seconds int When an API call is made with less than the specified number of seconds until the access token expires, or after expiry, it will refresh the token. Defaults to 5. 5 auth_retries Union[int, urllib3.util.retry.Retry] Number of times to attempt to authenticate to handle connection problems. Defaults to None. None Source code in fusion/fusion.py def __init__ ( self , credentials : Union [ FusionCredentials , Union [ str , dict ]], proxies : dict = {}, refresh_within_seconds : int = 5 , auth_retries : Union [ int , Retry ] = None , * args , ** kwargs , ) -> None : \"\"\"Class constructor to create a FusionOAuthAdapter object. Args: credentials (Union[FusionCredentials, Union[str, dict]): Valid user credentials to authenticate. proxies (dict, optional): Specify a proxy if required to access the authentication server. Defaults to {}. refresh_within_seconds (int, optional): When an API call is made with less than the specified number of seconds until the access token expires, or after expiry, it will refresh the token. Defaults to 5. auth_retries (Union[int, Retry]): Number of times to attempt to authenticate to handle connection problems. Defaults to None. \"\"\" super ( FusionOAuthAdapter , self ) . __init__ ( * args , ** kwargs ) if isinstance ( credentials , FusionCredentials ): self . credentials = credentials else : self . credentials = FusionCredentials . from_object ( credentials ) if proxies : self . proxies = proxies else : self . proxies = self . credentials . proxies self . bearer_token_expiry = datetime . datetime . now () self . number_token_refreshes = 0 self . refresh_within_seconds = refresh_within_seconds if not auth_retries : self . auth_retries = Retry ( total = 5 , backoff_factor = 0.2 ) else : self . auth_retries = Retry . from_int ( auth_retries ) send ( self , request , ** kwargs ) \u00b6 Function to send a request to the authentication server. Parameters: Name Type Description Default request requests.Session A HTTP Session. required Source code in fusion/fusion.py def send ( self , request , ** kwargs ): \"\"\"Function to send a request to the authentication server. Args: request (requests.Session): A HTTP Session. Returns: \"\"\" def _refresh_token_data (): payload = { \"grant_type\" : \"client_credentials\" , \"client_id\" : self . credentials . client_id , \"client_secret\" : self . credentials . client_secret , \"aud\" : self . credentials . resource , } try : s = requests . Session () s . mount ( 'http://' , HTTPAdapter ( max_retries = self . auth_retries )) response = s . post ( self . credentials . auth_url , data = payload ) response_data = response . json () access_token = response_data [ \"access_token\" ] expiry = response_data [ \"expires_in\" ] return access_token , expiry except Exception as ex : raise Exception ( f 'Failed to authenticate against OAuth server { ex } ' ) token_expires_in = ( self . bearer_token_expiry - datetime . datetime . now ()) . total_seconds () if token_expires_in < self . refresh_within_seconds : token , expiry = _refresh_token_data () self . token = token self . bearer_token_expiry = datetime . datetime . now () + timedelta ( seconds = int ( expiry )) self . number_token_refreshes += 1 logger . log ( VERBOSE_LVL , f 'Refreshed token { self . number_token_refreshes } time { _res_plural ( self . number_token_refreshes ) } ' , ) request . headers . update ({ 'Authorization' : f 'Bearer { self . token } ' , 'jpmc-token-provider' : 'authe' }) response = super ( FusionOAuthAdapter , self ) . send ( request , ** kwargs ) return response UnrecognizedFormatError \u00b6 UnrecognizedFormatError exception wrapper to handle format errors. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"Modules"},{"location":"api/#fusion.fusion","text":"Main Fusion module.","title":"fusion"},{"location":"api/#fusion.fusion.APIConnectError","text":"APIConnectError exception wrapper to handle API connection errors. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"APIConnectError"},{"location":"api/#fusion.fusion.APIRequestError","text":"APIRequestError exception wrapper to handle API request erorrs. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"APIRequestError"},{"location":"api/#fusion.fusion.APIResponseError","text":"APIResponseError exception wrapper to handle API response errors. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"APIResponseError"},{"location":"api/#fusion.fusion.CredentialError","text":"CredentialError exception wrapper to handle errors in credentials provided for authentication. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"CredentialError"},{"location":"api/#fusion.fusion.Fusion","text":"Core Fusion class for API access.","title":"Fusion"},{"location":"api/#fusion.fusion.Fusion.__init__","text":"Constructor to instantiate a new Fusion object. Parameters: Name Type Description Default credentials Union[str, dict] A path to a credentials file or a dictionary containing the required keys. Defaults to 'config/client_credentials.json'. 'config/client_credentials.json' root_url str The API root URL. Defaults to \"https://fusion-api.jpmorgan.com/fusion/v1/\". 'https://fusion-api.jpmorgan.com/fusion/v1/' download_folder str The folder path where downloaded data files are saved. Defaults to \"downloads\". 'downloads' log_level int Set the logging level. Defaults to logging.ERROR. 40 Source code in fusion/fusion.py def __init__ ( self , credentials : Union [ str , dict ] = 'config/client_credentials.json' , root_url : str = \"https://fusion-api.jpmorgan.com/fusion/v1/\" , download_folder : str = \"downloads\" , log_level : int = logging . ERROR , ) -> None : \"\"\"Constructor to instantiate a new Fusion object. Args: credentials (Union[str, dict], optional): A path to a credentials file or a dictionary containing the required keys. Defaults to 'config/client_credentials.json'. root_url (_type_, optional): The API root URL. Defaults to \"https://fusion-api.jpmorgan.com/fusion/v1/\". download_folder (str, optional): The folder path where downloaded data files are saved. Defaults to \"downloads\". log_level (int, optional): Set the logging level. Defaults to logging.ERROR. \"\"\" self . root_url = root_url self . download_folder = download_folder Path ( download_folder ) . mkdir ( parents = True , exist_ok = True ) if logger . hasHandlers (): logger . handlers . clear () file_handler = logging . FileHandler ( filename = \"fusion_sdk.log\" ) logging . addLevelName ( VERBOSE_LVL , \"VERBOSE\" ) stdout_handler = logging . StreamHandler ( sys . stdout ) formatter = logging . Formatter ( \" %(asctime)s . %(msecs)03d %(name)s : %(levelname)s %(message)s \" , datefmt = \"%Y-%m- %d %H:%M:%S\" ) stdout_handler . setFormatter ( formatter ) logger . addHandler ( stdout_handler ) logger . addHandler ( file_handler ) logger . setLevel ( log_level ) if isinstance ( credentials , FusionCredentials ): self . credentials = credentials else : self . credentials = FusionCredentials . from_object ( credentials ) self . session = _get_session ( self . credentials , self . root_url )","title":"__init__()"},{"location":"api/#fusion.fusion.Fusion.catalog_resources","text":"List the resources contained within the catalog, for example products and datasets. Parameters: Name Type Description Default catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each resource within the catalog Source code in fusion/fusion.py def catalog_resources ( self , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the resources contained within the catalog, for example products and datasets. Args: catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each resource within the catalog \"\"\" url = f ' { self . root_url } catalogs/ { catalog } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"catalog_resources()"},{"location":"api/#fusion.fusion.Fusion.dataset_resources","text":"List the resources available for a dataset, currently this will always be a datasetseries. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each resource Source code in fusion/fusion.py def dataset_resources ( self , dataset : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the resources available for a dataset, currently this will always be a datasetseries. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each resource \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"dataset_resources()"},{"location":"api/#fusion.fusion.Fusion.datasetmember_resources","text":"List the available resources for a datasetseries member. Parameters: Name Type Description Default dataset str A dataset identifier required series str The datasetseries identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each datasetseries member resource. Currently this will always be distributions. Source code in fusion/fusion.py def datasetmember_resources ( self , dataset : str , series : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the available resources for a datasetseries member. Args: dataset (str): A dataset identifier series (str): The datasetseries identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each datasetseries member resource. Currently this will always be distributions. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries/ { series } ' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"datasetmember_resources()"},{"location":"api/#fusion.fusion.Fusion.download","text":"Downloads the requested distributions of a dataset to disk. Parameters: Name Type Description Default dataset str A dataset identifier required dt_str str Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. 'latest' dataset_format str The file format, e.g. CSV or Parquet. Defaults to 'parquet'. 'parquet' catalog str A catalog identifier. Defaults to 'common'. 'common' n_par int Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. 5 show_progress bool Display a progress bar during data download Defaults to True. True force_download bool If True then will always download a file even if it is already on disk. Defaults to True. False download_folder str The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init None Source code in fusion/fusion.py def download ( self , dataset : str , dt_str : str = 'latest' , dataset_format : str = 'parquet' , catalog : str = 'common' , n_par : int = DEFAULT_PARALLELISM , show_progress : bool = True , force_download : bool = False , download_folder : str = None , ): \"\"\"Downloads the requested distributions of a dataset to disk. Args: dataset (str): A dataset identifier dt_str (str, optional): Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'. catalog (str, optional): A catalog identifier. Defaults to 'common'. n_par (int, optional): Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. show_progress (bool, optional): Display a progress bar during data download Defaults to True. force_download (bool, optional): If True then will always download a file even if it is already on disk. Defaults to True. download_folder (str, optional): The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in __init__ Returns: \"\"\" required_series = self . _resolve_distro_tuples ( dataset , dt_str , dataset_format , catalog ) if not download_folder : download_folder = self . download_folder Path ( download_folder ) . mkdir ( parents = True , exist_ok = True ) download_spec = [ ( self . credentials , _distribution_to_url ( self . root_url , series [ 1 ], series [ 2 ], series [ 3 ], series [ 0 ]), _distribution_to_filename ( download_folder , series [ 1 ], series [ 2 ], series [ 3 ], series [ 0 ]), force_download , ) for series in required_series ] if show_progress : loop = tqdm ( download_spec ) else : loop = download_spec logger . log ( VERBOSE_LVL , f 'Beginning { len ( loop ) } downloads in batches of { n_par } ' , ) res = Parallel ( n_jobs = n_par )( delayed ( _stream_single_file_new_session )( * spec ) for spec in loop ) return res","title":"download()"},{"location":"api/#fusion.fusion.Fusion.list_catalogs","text":"Lists the catalogs available to the API account. Parameters: Name Type Description Default output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each catalog Source code in fusion/fusion.py def list_catalogs ( self , output : bool = False ) -> pd . DataFrame : \"\"\"Lists the catalogs available to the API account. Args: output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each catalog \"\"\" url = f ' { self . root_url } catalogs/' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_catalogs()"},{"location":"api/#fusion.fusion.Fusion.list_dataset_attributes","text":"Returns the list of attributes that are in the dataset. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each attribute Source code in fusion/fusion.py def list_dataset_attributes ( self , dataset : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"Returns the list of attributes that are in the dataset. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each attribute \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /attributes' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_dataset_attributes()"},{"location":"api/#fusion.fusion.Fusion.list_datasetmembers","text":"List the available members in the dataset series. Parameters: Name Type Description Default dataset str A dataset identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each dataset member. Source code in fusion/fusion.py def list_datasetmembers ( self , dataset : str , catalog : str = 'common' , output : bool = False , max_results : int = - 1 ) -> pd . DataFrame : \"\"\"List the available members in the dataset series. Args: dataset (str): A dataset identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each dataset member. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries' df = Fusion . _call_for_dataframe ( url , self . session ) if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_datasetmembers()"},{"location":"api/#fusion.fusion.Fusion.list_datasets","text":"summary . Parameters: Name Type Description Default contains Union[str, list] A string or a list of strings that are dataset identifiers to filter the datasets list. If a list is provided then it will return datasets whose identifier matches any of the strings. Defaults to None. None id_contains bool Filter datasets only where the string(s) are contained in the identifier, ignoring description. False catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each dataset. Source code in fusion/fusion.py def list_datasets ( self , contains : Union [ str , list ] = None , id_contains : bool = False , catalog : str = 'common' , output : bool = False , max_results : int = - 1 , ) -> pd . DataFrame : \"\"\"_summary_. Args: contains (Union[str, list], optional): A string or a list of strings that are dataset identifiers to filter the datasets list. If a list is provided then it will return datasets whose identifier matches any of the strings. Defaults to None. id_contains (bool): Filter datasets only where the string(s) are contained in the identifier, ignoring description. catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each dataset. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets' df = Fusion . _call_for_dataframe ( url , self . session ) if contains : if isinstance ( contains , list ): contains = \"|\" . join ( f ' { s } ' for s in contains ) if id_contains : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False )] else : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False ) | df [ 'description' ] . str . contains ( contains , case = False ) ] if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_datasets()"},{"location":"api/#fusion.fusion.Fusion.list_distributions","text":"List the available distributions (downloadable instances of the dataset with a format type). Parameters: Name Type Description Default dataset str A dataset identifier required series str The datasetseries identifier required catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False Returns: Type Description DataFrame pandas.DataFrame: A dataframe with a row for each distribution. Source code in fusion/fusion.py def list_distributions ( self , dataset : str , series : str , catalog : str = 'common' , output : bool = False ) -> pd . DataFrame : \"\"\"List the available distributions (downloadable instances of the dataset with a format type). Args: dataset (str): A dataset identifier series (str): The datasetseries identifier catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. Returns: pandas.DataFrame: A dataframe with a row for each distribution. \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /datasets/ { dataset } /datasetseries/ { series } /distributions' df = Fusion . _call_for_dataframe ( url , self . session ) if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_distributions()"},{"location":"api/#fusion.fusion.Fusion.list_products","text":"Get the products contained in a catalog. A product is a grouping of datasets. Parameters: Name Type Description Default contains Union[str, list] A string or a list of strings that are product identifiers to filter the products list. If a list is provided then it will return products whose identifier matches any of the strings. Defaults to None. None id_contains bool Filter datasets only where the string(s) are contained in the identifier, ignoring description. False catalog str A catalog identifier. Defaults to 'common'. 'common' output bool If True then print the dataframe. Defaults to False. False max_results int Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. -1 Returns: Type Description DataFrame pandas.DataFrame: a dataframe with a row for each product Source code in fusion/fusion.py def list_products ( self , contains : Union [ str , list ] = None , id_contains : bool = False , catalog : str = 'common' , output : bool = False , max_results : int = - 1 , ) -> pd . DataFrame : \"\"\"Get the products contained in a catalog. A product is a grouping of datasets. Args: contains (Union[str, list], optional): A string or a list of strings that are product identifiers to filter the products list. If a list is provided then it will return products whose identifier matches any of the strings. Defaults to None. id_contains (bool): Filter datasets only where the string(s) are contained in the identifier, ignoring description. catalog (str, optional): A catalog identifier. Defaults to 'common'. output (bool, optional): If True then print the dataframe. Defaults to False. max_results (int, optional): Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results. Returns: pandas.DataFrame: a dataframe with a row for each product \"\"\" url = f ' { self . root_url } catalogs/ { catalog } /products' df = Fusion . _call_for_dataframe ( url , self . session ) if contains : if isinstance ( contains , list ): contains = \"|\" . join ( f ' { s } ' for s in contains ) if id_contains : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False )] else : df = df [ df [ 'identifier' ] . str . contains ( contains , case = False ) | df [ 'description' ] . str . contains ( contains , case = False ) ] if max_results > - 1 : df = df [ 0 : max_results ] if output : print ( tabulate ( df , headers = \"keys\" , tablefmt = \"psql\" )) return df","title":"list_products()"},{"location":"api/#fusion.fusion.Fusion.load","text":"Gets distributions for a specified date or date range and returns the data as a dataframe. Parameters: Name Type Description Default dataset str A dataset identifier required dt_str str Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. 'latest' dataset_format str The file format, e.g. CSV or Parquet. Defaults to 'parquet'. 'parquet' catalog str A catalog identifier. Defaults to 'common'. 'common' n_par int Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. 5 show_progress bool Display a progress bar during data download Defaults to True. True dry_run bool description . Defaults to True required columns List description . Defaults to None None force_download bool If True then will always download a file even if it is already on disk. Defaults to True. False download_folder str The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init None Returns: Type Description pandas.DataFrame a dataframe containing the requested data. If multiple dataset instances are retrieved then these are concatenated first. Source code in fusion/fusion.py def load ( self , dataset : str , dt_str : str = 'latest' , dataset_format : str = 'parquet' , catalog : str = 'common' , n_par : int = DEFAULT_PARALLELISM , show_progress : bool = True , columns : List = None , force_download : bool = False , download_folder : str = None , ** kwargs , ): \"\"\"Gets distributions for a specified date or date range and returns the data as a dataframe. Args: dataset (str): A dataset identifier dt_str (str, optional): Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'. catalog (str, optional): A catalog identifier. Defaults to 'common'. n_par (int, optional): Specify how many distributions to download in parallel. Defaults to DEFAULT_PARALLELISM. show_progress (bool, optional): Display a progress bar during data download Defaults to True. dry_run (bool, optional): _description_. Defaults to True columns (List, optional): _description_. Defaults to None force_download (bool, optional): If True then will always download a file even if it is already on disk. Defaults to True. download_folder (str, optional): The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in __init__ Returns: pandas.DataFrame: a dataframe containing the requested data. If multiple dataset instances are retrieved then these are concatenated first. \"\"\" if not download_folder : download_folder = self . download_folder download_res = self . download ( dataset , dt_str , dataset_format , catalog , n_par , show_progress , force_download , download_folder ) if not all ( res [ 0 ] for res in download_res ): failed_res = [ res for res in download_res if not res [ 0 ]] raise Exception ( f \"Not all downloads were successfully completed. \" f \"Re-run to collect missing files. The following failed: \\n { failed_res } \" ) files = [ res [ 1 ] for res in download_res ] pd_read_fn_map = { 'csv' : pd . read_csv , 'parquet' : pd . read_parquet , 'parq' : pd . read_parquet , 'json' : pd . read_json , } pd_read_default_kwargs : Dict [ str , Dict [ str , object ]] = { 'csv' : { 'sep' : ',' , 'header' : 0 , 'low_memory' : True }, 'parquet' : { 'columns' : columns }, } pd_read_default_kwargs [ 'parq' ] = pd_read_default_kwargs [ 'parquet' ] pd_reader = pd_read_fn_map . get ( dataset_format ) pd_read_kwargs = pd_read_default_kwargs . get ( dataset_format , {}) if not pd_reader : raise Exception ( f 'No pandas function to read file in format { dataset_format } ' ) pd_read_kwargs . update ( kwargs ) dataframes = ( pd_reader ( f , ** pd_read_kwargs ) for f in files ) df = pd . concat ( dataframes , ignore_index = True ) return df","title":"load()"},{"location":"api/#fusion.fusion.FusionCredentials","text":"Utility functions to manage credentials.","title":"FusionCredentials"},{"location":"api/#fusion.fusion.FusionCredentials.__init__","text":"Constuctor for the FusionCredentials authentication management class. Parameters: Name Type Description Default client_id str A valid OAuth client identifier. Defaults to None. None client_secret str A valid OAuth client secret. Defaults to None. None resource str The OAuth audience. Defaults to None. None auth_url str URL for the OAuth authentication server. Defaults to None. None proxies dict Any proxy servers required to route HTTP and HTTPS requests to the internet. {} Source code in fusion/fusion.py def __init__ ( self , client_id : str = None , client_secret : str = None , resource : str = None , auth_url : str = None , proxies = {}, ) -> None : \"\"\"Constuctor for the FusionCredentials authentication management class. Args: client_id (str, optional): A valid OAuth client identifier. Defaults to None. client_secret (str, optional): A valid OAuth client secret. Defaults to None. resource (str, optional): The OAuth audience. Defaults to None. auth_url (str, optional): URL for the OAuth authentication server. Defaults to None. proxies (dict, optional): Any proxy servers required to route HTTP and HTTPS requests to the internet. \"\"\" self . client_id = client_id self . client_secret = client_secret self . resource = resource self . auth_url = auth_url self . proxies = proxies","title":"__init__()"},{"location":"api/#fusion.fusion.FusionCredentials.from_dict","text":"Create a credentials object from a dictionary. Parameters: Name Type Description Default credentials dict A dictionary containing the requried keys: client_id, client_secret, resource, auth_url, and optionally proxies required Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_dict ( credentials : dict ): \"\"\"Create a credentials object from a dictionary. Args: credentials (dict): A dictionary containing the requried keys: client_id, client_secret, resource, auth_url, and optionally proxies Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" client_id = credentials [ 'client_id' ] client_secret = credentials [ 'client_secret' ] resource = credentials [ 'resource' ] auth_url = credentials [ 'auth_url' ] proxies = credentials . get ( 'proxies' ) creds = FusionCredentials ( client_id , client_secret , resource , auth_url , proxies ) return creds","title":"from_dict()"},{"location":"api/#fusion.fusion.FusionCredentials.from_file","text":"Create a credentils object from a file. Parameters: Name Type Description Default credentials_file str Path (absolute or relative) and filename to load credentials from. Defaults to 'config/client.credentials.json'. 'config/client.credentials.json' Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_file ( credentials_file : str = 'config/client.credentials.json' ): \"\"\"Create a credentils object from a file. Args: credentials_file (str, optional): Path (absolute or relative) and filename to load credentials from. Defaults to 'config/client.credentials.json'. Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" with open ( credentials_file , 'r' ) as credentials : data = json . load ( credentials ) credentials = FusionCredentials . from_dict ( data ) return credentials","title":"from_file()"},{"location":"api/#fusion.fusion.FusionCredentials.from_object","text":"Utility function that will determine how to create a credentials object based on data passed. Parameters: Name Type Description Default credentials_source Union[str, dict] A string which could be a filename or a JSON object, or a dictionary. required Exceptions: Type Description CredentialError Exception raised when the provided credentials is not one of the supported types Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def from_object ( credentials_source : Union [ str , dict ]): \"\"\"Utility function that will determine how to create a credentials object based on data passed. Args: credentials_source (Union[str, dict]): A string which could be a filename or a JSON object, or a dictionary. Raises: CredentialError: Exception raised when the provided credentials is not one of the supported types Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" if isinstance ( credentials_source , dict ): return FusionCredentials . from_dict ( credentials_source ) elif isinstance ( credentials_source , str ): if _is_json ( credentials_source ): return FusionCredentials . from_dict ( json . loads ( credentials_source )) else : return FusionCredentials . from_file ( credentials_source ) raise CredentialError ( f 'Could not resolve the credentials provided: { credentials_source } ' )","title":"from_object()"},{"location":"api/#fusion.fusion.FusionCredentials.generate_credentials_file","text":"Utility function to generate credentials file that can be used for authentication. Parameters: Name Type Description Default credentials_file str The path and filename to store the credentials under. Path may be absolute or relative to current working directory. Defaults to 'config/client_credentials.json'. 'config/client_credentials.json' client_id str A valid OAuth client identifier. Defaults to None. None client_secret str A valid OAuth client secret. Defaults to None. None resource str The OAuth audience. Defaults to None. None auth_url str URL for the OAuth authentication server. Defaults to None. None proxies str Any proxy servers required to route HTTP and HTTPS requests to the internet. Defaults to {}. Keys are http and https None Exceptions: Type Description CredentialError Exception to handle missing values required for authentication. Returns: Type Description FusionCredentials a credentials object that can be used for authentication. Source code in fusion/fusion.py @staticmethod def generate_credentials_file ( credentials_file : str = 'config/client_credentials.json' , client_id : str = None , client_secret : str = None , resource : str = None , auth_url : str = None , proxies : str = None , ): \"\"\"Utility function to generate credentials file that can be used for authentication. Args: credentials_file (str, optional): The path and filename to store the credentials under. Path may be absolute or relative to current working directory. Defaults to 'config/client_credentials.json'. client_id (str, optional): A valid OAuth client identifier. Defaults to None. client_secret (str, optional): A valid OAuth client secret. Defaults to None. resource (str, optional): The OAuth audience. Defaults to None. auth_url (str, optional): URL for the OAuth authentication server. Defaults to None. proxies (dict, optional): Any proxy servers required to route HTTP and HTTPS requests to the internet. Defaults to {}. Keys are http and https Raises: CredentialError: Exception to handle missing values required for authentication. Returns: FusionCredentials: a credentials object that can be used for authentication. \"\"\" if not client_id : raise CredentialError ( 'A valid client_id is required' ) if not client_secret : raise CredentialError ( 'A valid client secret is required' ) if not resource : raise CredentialError ( 'A valid resource is required' ) if not auth_url : raise CredentialError ( 'A valid authentication server URL is required' ) data = dict ( { 'client_id' : client_id , 'client_secret' : client_secret , 'resource' : resource , 'auth_url' : auth_url } ) if proxies : proxies_dict = json . loads ( proxies ) data [ 'proxies' ] = proxies_dict json_data = json . dumps ( data ) with open ( credentials_file , 'w' ) as credentialsfile : credentialsfile . write ( json_data ) credentials = FusionCredentials ( client_id , client_secret , resource , auth_url ) return credentials","title":"generate_credentials_file()"},{"location":"api/#fusion.fusion.FusionOAuthAdapter","text":"An OAuth adapter to manage authentication and session tokens.","title":"FusionOAuthAdapter"},{"location":"api/#fusion.fusion.FusionOAuthAdapter.__init__","text":"Class constructor to create a FusionOAuthAdapter object. Parameters: Name Type Description Default credentials Union[fusion.fusion.FusionCredentials, str, dict] Valid user credentials to authenticate. required proxies dict Specify a proxy if required to access the authentication server. Defaults to {}. {} refresh_within_seconds int When an API call is made with less than the specified number of seconds until the access token expires, or after expiry, it will refresh the token. Defaults to 5. 5 auth_retries Union[int, urllib3.util.retry.Retry] Number of times to attempt to authenticate to handle connection problems. Defaults to None. None Source code in fusion/fusion.py def __init__ ( self , credentials : Union [ FusionCredentials , Union [ str , dict ]], proxies : dict = {}, refresh_within_seconds : int = 5 , auth_retries : Union [ int , Retry ] = None , * args , ** kwargs , ) -> None : \"\"\"Class constructor to create a FusionOAuthAdapter object. Args: credentials (Union[FusionCredentials, Union[str, dict]): Valid user credentials to authenticate. proxies (dict, optional): Specify a proxy if required to access the authentication server. Defaults to {}. refresh_within_seconds (int, optional): When an API call is made with less than the specified number of seconds until the access token expires, or after expiry, it will refresh the token. Defaults to 5. auth_retries (Union[int, Retry]): Number of times to attempt to authenticate to handle connection problems. Defaults to None. \"\"\" super ( FusionOAuthAdapter , self ) . __init__ ( * args , ** kwargs ) if isinstance ( credentials , FusionCredentials ): self . credentials = credentials else : self . credentials = FusionCredentials . from_object ( credentials ) if proxies : self . proxies = proxies else : self . proxies = self . credentials . proxies self . bearer_token_expiry = datetime . datetime . now () self . number_token_refreshes = 0 self . refresh_within_seconds = refresh_within_seconds if not auth_retries : self . auth_retries = Retry ( total = 5 , backoff_factor = 0.2 ) else : self . auth_retries = Retry . from_int ( auth_retries )","title":"__init__()"},{"location":"api/#fusion.fusion.FusionOAuthAdapter.send","text":"Function to send a request to the authentication server. Parameters: Name Type Description Default request requests.Session A HTTP Session. required Source code in fusion/fusion.py def send ( self , request , ** kwargs ): \"\"\"Function to send a request to the authentication server. Args: request (requests.Session): A HTTP Session. Returns: \"\"\" def _refresh_token_data (): payload = { \"grant_type\" : \"client_credentials\" , \"client_id\" : self . credentials . client_id , \"client_secret\" : self . credentials . client_secret , \"aud\" : self . credentials . resource , } try : s = requests . Session () s . mount ( 'http://' , HTTPAdapter ( max_retries = self . auth_retries )) response = s . post ( self . credentials . auth_url , data = payload ) response_data = response . json () access_token = response_data [ \"access_token\" ] expiry = response_data [ \"expires_in\" ] return access_token , expiry except Exception as ex : raise Exception ( f 'Failed to authenticate against OAuth server { ex } ' ) token_expires_in = ( self . bearer_token_expiry - datetime . datetime . now ()) . total_seconds () if token_expires_in < self . refresh_within_seconds : token , expiry = _refresh_token_data () self . token = token self . bearer_token_expiry = datetime . datetime . now () + timedelta ( seconds = int ( expiry )) self . number_token_refreshes += 1 logger . log ( VERBOSE_LVL , f 'Refreshed token { self . number_token_refreshes } time { _res_plural ( self . number_token_refreshes ) } ' , ) request . headers . update ({ 'Authorization' : f 'Bearer { self . token } ' , 'jpmc-token-provider' : 'authe' }) response = super ( FusionOAuthAdapter , self ) . send ( request , ** kwargs ) return response","title":"send()"},{"location":"api/#fusion.fusion.UnrecognizedFormatError","text":"UnrecognizedFormatError exception wrapper to handle format errors. Parameters: Name Type Description Default Exception Exception to wrap. required","title":"UnrecognizedFormatError"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.0.1] - 2022-05-12 \u00b6 First live release on JPMC gitub [1.0.2] - 2022-05-12 \u00b6 Integrate build with docs [1.0.3] - 2022-05-12 \u00b6 Add support for 'latest' datasets","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#101---2022-05-12","text":"First live release on JPMC gitub","title":"[1.0.1] - 2022-05-12"},{"location":"changelog/#102---2022-05-12","text":"Integrate build with docs","title":"[1.0.2] - 2022-05-12"},{"location":"changelog/#103---2022-05-12","text":"Add support for 'latest' datasets","title":"[1.0.3] - 2022-05-12"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 {{ cookiecutter.project_name }} could always use more documentation, whether as part of the official {{ cookiecutter.project_name }} docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up {{ cookiecutter.project_slug }} for local development. Fork the {{ cookiecutter.project_slug }} repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/{{ cookiecutter.project_slug }}.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.7, 3.8 and 3.9. Check https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_{{ cookiecutter.pkg_name }}.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"{{ cookiecutter.project_name }} could always use more documentation, whether as part of the official {{ cookiecutter.project_name }} docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up {{ cookiecutter.project_slug }} for local development. Fork the {{ cookiecutter.project_slug }} repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/{{ cookiecutter.project_slug }}.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.7, 3.8 and 3.9. Check https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_{{ cookiecutter.pkg_name }}.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install PyFusion, run this command in your terminal: $ pip install pyfusion This is the preferred method to install PyFusion, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for PyFusion can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/jpmorganchase/fusion Or download the tarball : $ curl -OJL https://github.com/jpmorganchase/fusion/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install PyFusion, run this command in your terminal: $ pip install pyfusion This is the preferred method to install PyFusion, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for PyFusion can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/jpmorganchase/fusion Or download the tarball : $ curl -OJL https://github.com/jpmorganchase/fusion/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"PyFusion \u00b6 PyFusion is the Python SDK for the Fusion platform API. Installation \u00b6 pip install pyfusion","title":"Usage"},{"location":"usage/#pyfusion","text":"PyFusion is the Python SDK for the Fusion platform API.","title":"PyFusion"},{"location":"usage/#installation","text":"pip install pyfusion","title":"Installation"}]}